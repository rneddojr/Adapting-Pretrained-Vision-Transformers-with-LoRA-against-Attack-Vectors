{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "492fb3f3",
   "metadata": {},
   "source": [
    "**A comprehensive Python notebook for training a LoRA adapter on a Vision Transformer (ViT) model using PEFT.**\n",
    "\n",
    "Here's what the notebook covers:\n",
    "Key Features:\n",
    "\n",
    "1. <b>LoRA Configuration:</b> Uses rank-16 LoRA adapters on the attention layers (query and value projections), which dramatically reduces trainable parameters\n",
    "\n",
    "2. <b>Dataset:</b> Uses Food101 as an example (you can easily swap this with your own dataset)\n",
    "\n",
    "3. <b>Data Augmentation:</b> Includes random cropping and horizontal flipping for training\n",
    "\n",
    "4. <b>Training:</b> Configured with 3 epochs, evaluation during training, and automatic best model selection\n",
    "\n",
    "5. <b>Metrics:</b> Computes accuracy and F1 score\n",
    "\n",
    "6. <b>Inference Example:</b> Shows how to load and use the trained LoRA adapter\n",
    "\n",
    "Key Parameters to Adjust:\n",
    "\n",
    "- *r* :--> LoRA rank (higher = more parameters but potentially better performance)\n",
    "- *lora_alpha* :--> Scaling factor (typically set equal to r)\n",
    "- *target_modules* :--> Which layers to apply LoRA to\n",
    "- *learning_rate* :--> Start with 5e-4 for LoRA, adjust as needed\n",
    "- *Dataset* :--> food101 currently in use\n",
    "\n",
    "The notebook will print the number of trainable parameters, showing you the efficiency of LoRA (typically only 0.1-1% of total parameters need to be trained). The final model saves only the LoRA adapter weights, which are very small compared to the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9776ebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# LoRA Fine-tuning Vision Transformer (ViT) with PEFT\n",
    "# This notebook demonstrates parameter-efficient fine-tuning of ViT for image classification\n",
    "\n",
    "# Install required packages\n",
    "# !pip install transformers datasets peft pillow torch torchvision accelerate\n",
    "\n",
    "import torch\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6056e437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Number of classes: 101\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. Load and Prepare Dataset\n",
    "# ============================================================================\n",
    "# Using a sample dataset (food101 subset for demo - you can replace with your own)\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(\"food101\", split=\"train[:2%]\")  # Using 2% for demo\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Get label information\n",
    "labels = dataset[\"train\"].features[\"label\"].names\n",
    "num_labels = len(labels)\n",
    "print(f\"Number of classes: {num_labels}\")\n",
    "# print(labels[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "987733e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing model and processor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. Initialize Model and Processor\n",
    "# ============================================================================\n",
    "print(\"\\nInitializing model and processor...\")\n",
    "model_name = \"google/vit-base-patch16-224-in21k\"\n",
    "processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Load pre-trained ViT model\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label={str(i): label for i, label in enumerate(labels)},\n",
    "    label2id={label: str(i) for i, label in enumerate(labels)},\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e9d36aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuring LoRA...\n",
      "trainable params: 225,125 || all params: 86,101,450 || trainable%: 0.2615\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3. Configure LoRA\n",
    "# ============================================================================\n",
    "print(\"\\nConfiguring LoRA...\")\n",
    "lora_config = LoraConfig(\n",
    "    r=4,  # Rank of the low-rank matrices\n",
    "    lora_alpha=16,  # Scaling factor\n",
    "    target_modules=[\"query\", \"value\"],  # Apply LoRA to attention layers\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"classifier\"],  # Train the classification head fully\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "# model.unload() # to be used when re-running\n",
    "model = get_peft_model(model=model, peft_config=lora_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e47f088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 3030\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 758\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "080f2204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing data transforms...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4. Data Preprocessing\n",
    "# ============================================================================\n",
    "print(\"\\nPreparing data transforms...\")\n",
    "\n",
    "# Define transforms for training\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(processor.size[\"height\"]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std),\n",
    "])\n",
    "\n",
    "# Define transforms for validation\n",
    "val_transforms = transforms.Compose([\n",
    "    lambda img: img.resize((processor.size[\"height\"], processor.size[\"width\"])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std),\n",
    "])\n",
    "\n",
    "def preprocess_train(examples):\n",
    "    \"\"\"Preprocess training images\"\"\"\n",
    "    examples[\"pixel_values\"] = [\n",
    "        train_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]\n",
    "    ]\n",
    "    return examples\n",
    "\n",
    "def preprocess_val(examples):\n",
    "    \"\"\"Preprocess validation images\"\"\"\n",
    "    examples[\"pixel_values\"] = [\n",
    "        val_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]\n",
    "    ]\n",
    "    return examples\n",
    "\n",
    "# Apply preprocessing\n",
    "train_dataset = dataset[\"train\"].with_transform(preprocess_train)\n",
    "val_dataset = dataset[\"test\"].with_transform(preprocess_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80329a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 5. Define Metrics\n",
    "# ============================================================================\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute accuracy and F1 score\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f6d8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 6. Define Collator\n",
    "# ============================================================================\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collator to stack images and labels\"\"\"\n",
    "    return {\n",
    "        \"pixel_values\": torch.stack([x[\"pixel_values\"] for x in batch]),\n",
    "        \"labels\": torch.tensor([x[\"label\"] for x in batch])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f738f1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up training configuration...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 7. Training Configuration\n",
    "# ============================================================================\n",
    "print(\"\\nSetting up training configuration...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./vit_lora_finetuned\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=5e-3,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",  # Change to \"wandb\" or \"tensorboard\" if you want logging\n",
    "    fp16=torch.cuda.is_available(),  # Use mixed precision if GPU available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "895e77ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing trainer...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 8. Initialize Trainer\n",
    "# ============================================================================\n",
    "print(\"\\nInitializing trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    processing_class=processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a29a99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 46:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.283800</td>\n",
       "      <td>0.145584</td>\n",
       "      <td>0.961741</td>\n",
       "      <td>0.958685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.476300</td>\n",
       "      <td>0.290060</td>\n",
       "      <td>0.902375</td>\n",
       "      <td>0.902764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.357800</td>\n",
       "      <td>0.196565</td>\n",
       "      <td>0.935356</td>\n",
       "      <td>0.935058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.262000</td>\n",
       "      <td>0.233288</td>\n",
       "      <td>0.922164</td>\n",
       "      <td>0.921699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.327400</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.953826</td>\n",
       "      <td>0.953892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.283500</td>\n",
       "      <td>0.204269</td>\n",
       "      <td>0.932718</td>\n",
       "      <td>0.932300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.230200</td>\n",
       "      <td>0.118851</td>\n",
       "      <td>0.969657</td>\n",
       "      <td>0.969292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.223100</td>\n",
       "      <td>0.206280</td>\n",
       "      <td>0.930079</td>\n",
       "      <td>0.928777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.134148</td>\n",
       "      <td>0.957784</td>\n",
       "      <td>0.957782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.124380</td>\n",
       "      <td>0.959103</td>\n",
       "      <td>0.958899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.073900</td>\n",
       "      <td>0.105583</td>\n",
       "      <td>0.968338</td>\n",
       "      <td>0.968223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 01:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "  eval_loss: 0.1189\n",
      "  eval_accuracy: 0.9697\n",
      "  eval_f1: 0.9693\n",
      "  eval_runtime: 68.6757\n",
      "  eval_samples_per_second: 11.0370\n",
      "  eval_steps_per_second: 0.6990\n",
      "  epoch: 3.0000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 9. Train the Model\n",
    "# ============================================================================\n",
    "print(\"\\nStarting training...\")\n",
    "train_results = trainer.train()\n",
    "\n",
    "# ============================================================================\n",
    "# 10. Evaluate the Model\n",
    "# ============================================================================\n",
    "print(\"\\nEvaluating model...\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"\\nEvaluation Results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256dc17d",
   "metadata": {},
   "source": [
    "1. **LoRA Adapter only** ```(./vit_lora_adapter)``` - Small file size, requires base model for inference\n",
    "2. **Merged Model** ```(./vit_lora_merged)``` - Standalone model with LoRA weights merged into base model, larger file size but easier to deploy\n",
    "\n",
    "The inference section now demonstrates both approaches:\n",
    "\n",
    "- Loading the LoRA adapter (requires loading base model first)\n",
    "- Loading the merged model directly (no base model needed)\n",
    "\n",
    "The merged model is particularly useful for deployment scenarios where you want a single, self-contained model without managing separate base model and adapter files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2183c853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving LoRA adapter...\n",
      "LoRA adapter saved successfully!\n",
      "\n",
      "Merging LoRA weights with base model...\n",
      "Merged model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 11. Save the Model\n",
    "# ============================================================================\n",
    "print(\"\\nSaving LoRA adapter...\")\n",
    "model.save_pretrained(\"./vit_lora_adapter\")\n",
    "processor.save_pretrained(\"./vit_lora_adapter\")\n",
    "print(\"LoRA adapter saved successfully!\")\n",
    "\n",
    "# Merge LoRA weights with base model and save the composed model\n",
    "print(\"\\nMerging LoRA weights with base model...\")\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\"./vit_lora_merged\")\n",
    "processor.save_pretrained(\"./vit_lora_merged\")\n",
    "print(\"Merged model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b8af53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "INFERENCE EXAMPLE\n",
      "==================================================\n",
      "\n",
      "--- Using Merged Model ---\n",
      "Predicted class: hamburger\n",
      "Actual class: hamburger\n",
      "\n",
      "âœ… First training complete!\n",
      "   - LoRA adapter saved to: ./vit_lora_adapter\n",
      "   - Merged model saved to: ./vit_lora_merged\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 12. Inference Example\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"INFERENCE EXAMPLE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get a sample image from validation set\n",
    "sample_image = val_dataset[0][\"image\"]\n",
    "\n",
    "# Preprocess\n",
    "inputs = processor(images=sample_image, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Option 1: Load merged model (no need for base model)\n",
    "print(\"\\n--- Using Merged Model ---\")\n",
    "merged_model = ViTForImageClassification.from_pretrained(\"./vit_lora_merged\")\n",
    "merged_model.eval()\n",
    "merged_model.to(device)\n",
    "\n",
    "# Predict with merged model\n",
    "with torch.no_grad():\n",
    "    outputs = merged_model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_idx = logits.argmax(-1).item()\n",
    "\n",
    "print(f\"Predicted class: {labels[predicted_class_idx]}\")\n",
    "print(f\"Actual class: {labels[val_dataset[0]['label']]}\")\n",
    "\n",
    "print(\"\\nâœ… First training complete!\")\n",
    "print(\"   - LoRA adapter saved to: ./vit_lora_adapter\")\n",
    "print(\"   - Merged model saved to: ./vit_lora_merged\")\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # Option 2: Load LoRA adapter (smaller file size)\n",
    "# print(\"\\n--- Using LoRA Adapter ---\")\n",
    "# base_model = ViTForImageClassification.from_pretrained( #load base model\n",
    "#     model_name,\n",
    "#     num_labels=num_labels,\n",
    "#     ignore_mismatched_sizes=True\n",
    "# )\n",
    "# inference_model = PeftModel.from_pretrained(base_model, \"./vit_lora_adapter\") #load lora adapter\n",
    "# inference_model.eval()\n",
    "# inference_model.to(device)\n",
    "\n",
    "# # Predict\n",
    "# with torch.no_grad():\n",
    "#     outputs = inference_model(**inputs)\n",
    "#     logits = outputs.logits\n",
    "#     predicted_class_idx = logits.argmax(-1).item()\n",
    "\n",
    "# print(f\"Predicted class: {labels[predicted_class_idx]}\")\n",
    "# print(f\"Actual class: {labels[val_dataset[0]['label']]}\")\n",
    "\n",
    "# print(\"\\nâœ… Training complete! LoRA adapter has been trained and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12845445",
   "metadata": {},
   "source": [
    "**Section 13 - Add Noise and Test:**\n",
    "- Adds Gaussian noise to the validation data (30% noise level)\n",
    "- Tests the first composed model on noisy data to see how it performs\n",
    "\n",
    "\n",
    "**Section 14 - Train Second LoRA:**\n",
    "- Creates a noisy training dataset\n",
    "- Loads the first composed model as the base\n",
    "- Applies a second LoRA adapter on top of it\n",
    "- Trains on the noisy data to adapt to noise\n",
    "\n",
    "\n",
    "**Section 15 - Save Second Composed Model:**\n",
    "\n",
    "- Saves the second LoRA adapter\n",
    "- Merges and saves the second composed model (LoRA 1 + LoRA 2)\n",
    "\n",
    "\n",
    "**Section 16 - Final Comparison:**\n",
    "\n",
    "- Compares both models on clean and noisy data\n",
    "- Shows performance summary to see if the second LoRA improved robustness\n",
    "\n",
    "\n",
    "This demonstrates iterative LoRA training where you can stack multiple LoRA adapters by training each one on top of the previous composed model. The second LoRA learns to handle noisy data while preserving the knowledge from the first training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f47dcfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TESTING WITH NOISY DATA\n",
      "==================================================\n",
      "\n",
      "Creating noisy validation dataset...\n",
      "\n",
      "Evaluating merged model on noisy data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55283/1412891558.py:37: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  noisy_trainer = Trainer(\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 01:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Noisy Data Evaluation Results:\n",
      "  eval_loss: 1.5316\n",
      "  eval_model_preparation_time: 0.0024\n",
      "  eval_accuracy: 0.4749\n",
      "  eval_f1: 0.4483\n",
      "  eval_runtime: 64.2474\n",
      "  eval_samples_per_second: 11.7980\n",
      "  eval_steps_per_second: 0.7470\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 13. Add Noise to Data and Test Composed Model\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TESTING WITH NOISY DATA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from torchvision.transforms import GaussianBlur\n",
    "import random\n",
    "\n",
    "def add_noise_transform(noise_level=0.3):\n",
    "    \"\"\"Create transform that adds noise to images\"\"\"\n",
    "    return transforms.Compose([\n",
    "        lambda img: img.resize((processor.size[\"height\"], processor.size[\"width\"])),\n",
    "        transforms.ToTensor(),\n",
    "        lambda x: x + torch.randn_like(x) * noise_level,  # Add Gaussian noise\n",
    "        lambda x: torch.clamp(x, 0, 1),  # Clamp values to valid range\n",
    "        transforms.Normalize(mean=processor.image_mean, std=processor.image_std),\n",
    "    ])\n",
    "\n",
    "def preprocess_noisy(examples, noise_level=0.3):\n",
    "    \"\"\"Preprocess images with added noise\"\"\"\n",
    "    transform = add_noise_transform(noise_level)\n",
    "    examples[\"pixel_values\"] = [\n",
    "        transform(img.convert(\"RGB\")) for img in examples[\"image\"]\n",
    "    ]\n",
    "    return examples\n",
    "\n",
    "# Create noisy validation dataset\n",
    "print(\"\\nCreating noisy validation dataset...\")\n",
    "noisy_val_dataset = dataset[\"test\"].with_transform(\n",
    "    lambda ex: preprocess_noisy(ex, noise_level=0.3)\n",
    ")\n",
    "\n",
    "# Test merged model on noisy data\n",
    "print(\"\\nEvaluating merged model on noisy data...\")\n",
    "noisy_trainer = Trainer(\n",
    "    model=merged_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./temp\",\n",
    "        per_device_eval_batch_size=16,\n",
    "        remove_unused_columns=False,\n",
    "        report_to=\"none\"\n",
    "    ),\n",
    "    eval_dataset=noisy_val_dataset,\n",
    "    tokenizer=processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    ")\n",
    "\n",
    "noisy_eval_results = noisy_trainer.evaluate()\n",
    "print(f\"\\nNoisy Data Evaluation Results:\")\n",
    "for key, value in noisy_eval_results.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9713f297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TRAINING SECOND LORA ON COMPOSED MODEL\n",
      "==================================================\n",
      "\n",
      "Preparing noisy training dataset...\n",
      "\n",
      "Loading first composed model...\n",
      "\n",
      "Configuring second LoRA...\n",
      "\n",
      "Second LoRA trainable parameters:\n",
      "trainable params: 667,493 || all params: 86,543,818 || trainable%: 0.7713\n",
      "\n",
      "Setting up second training configuration...\n",
      "\n",
      "Initializing second trainer...\n",
      "\n",
      "Starting second LoRA training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55283/486252181.py:58: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  second_trainer = Trainer(\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 53:49, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>0.689426</td>\n",
       "      <td>0.773087</td>\n",
       "      <td>0.771061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.545500</td>\n",
       "      <td>0.521339</td>\n",
       "      <td>0.827177</td>\n",
       "      <td>0.823966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.304100</td>\n",
       "      <td>0.458816</td>\n",
       "      <td>0.837731</td>\n",
       "      <td>0.836830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.455300</td>\n",
       "      <td>0.438597</td>\n",
       "      <td>0.840369</td>\n",
       "      <td>0.840236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>0.384517</td>\n",
       "      <td>0.873351</td>\n",
       "      <td>0.872433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.434300</td>\n",
       "      <td>0.392466</td>\n",
       "      <td>0.873351</td>\n",
       "      <td>0.873192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.265100</td>\n",
       "      <td>0.389520</td>\n",
       "      <td>0.873351</td>\n",
       "      <td>0.872572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.337733</td>\n",
       "      <td>0.885224</td>\n",
       "      <td>0.885176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>0.375041</td>\n",
       "      <td>0.873351</td>\n",
       "      <td>0.873050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.340367</td>\n",
       "      <td>0.879947</td>\n",
       "      <td>0.879693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.235500</td>\n",
       "      <td>0.355617</td>\n",
       "      <td>0.882586</td>\n",
       "      <td>0.881831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating second composed model on noisy data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 01:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Second Model Evaluation Results:\n",
      "  eval_loss: 0.3469\n",
      "  eval_accuracy: 0.8852\n",
      "  eval_f1: 0.8848\n",
      "  eval_runtime: 69.0327\n",
      "  eval_samples_per_second: 10.9800\n",
      "  eval_steps_per_second: 0.6950\n",
      "  epoch: 3.0000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 14. Train Second LoRA on Composed Model\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING SECOND LORA ON COMPOSED MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Prepare noisy training dataset\n",
    "print(\"\\nPreparing noisy training dataset...\")\n",
    "noisy_train_dataset = dataset[\"train\"].with_transform(\n",
    "    lambda ex: preprocess_noisy(ex, noise_level=0.3)\n",
    ")\n",
    "\n",
    "# Load the merged model (first composed model)\n",
    "print(\"\\nLoading first composed model...\")\n",
    "second_base_model = ViTForImageClassification.from_pretrained(\"./vit_lora_merged\")\n",
    "\n",
    "# Configure second LoRA\n",
    "print(\"\\nConfiguring second LoRA...\")\n",
    "second_lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"classifier\"],\n",
    ")\n",
    "\n",
    "# Apply second LoRA to the composed model\n",
    "second_lora_model = get_peft_model(second_base_model, second_lora_config)\n",
    "print(\"\\nSecond LoRA trainable parameters:\")\n",
    "second_lora_model.print_trainable_parameters()\n",
    "\n",
    "# Training configuration for second LoRA\n",
    "print(\"\\nSetting up second training configuration...\")\n",
    "second_training_args = TrainingArguments(\n",
    "    output_dir=\"./vit_lora2_finetuned\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=5e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "# Initialize second trainer\n",
    "print(\"\\nInitializing second trainer...\")\n",
    "second_trainer = Trainer(\n",
    "    model=second_lora_model,\n",
    "    args=second_training_args,\n",
    "    train_dataset=noisy_train_dataset,\n",
    "    eval_dataset=noisy_val_dataset,\n",
    "    processing_class=processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    ")\n",
    "\n",
    "# Train second LoRA\n",
    "print(\"\\nStarting second LoRA training...\")\n",
    "second_train_results = second_trainer.train()\n",
    "\n",
    "# Evaluate second LoRA\n",
    "print(\"\\nEvaluating second composed model on noisy data...\")\n",
    "second_eval_results = second_trainer.evaluate()\n",
    "print(f\"\\nSecond Model Evaluation Results:\")\n",
    "for key, value in second_eval_results.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "844555fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving second LoRA adapter...\n",
      "Second LoRA adapter saved successfully!\n",
      "\n",
      "Merging second LoRA weights with model...\n",
      "Second merged model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 15. Save Second Composed Model\n",
    "# ============================================================================\n",
    "print(\"\\nSaving second LoRA adapter...\")\n",
    "second_lora_model.save_pretrained(\"./vit_lora2_adapter\")\n",
    "processor.save_pretrained(\"./vit_lora2_adapter\")\n",
    "print(\"Second LoRA adapter saved successfully!\")\n",
    "\n",
    "# Merge second LoRA weights and save\n",
    "print(\"\\nMerging second LoRA weights with model...\")\n",
    "second_merged_model = second_lora_model.merge_and_unload()\n",
    "second_merged_model.save_pretrained(\"./vit_lora2_merged\")\n",
    "processor.save_pretrained(\"./vit_lora2_merged\")\n",
    "print(\"Second merged model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6745a83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FINAL COMPARISON\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 01:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55283/322231783.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  clean_eval_second = Trainer(\n",
      "/home/emmanuel/anaconda3/envs/lora-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 01:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Performance Summary:\n",
      "\n",
      "First Composed Model (LoRA 1):\n",
      "  Clean data accuracy: 0.9697\n",
      "  Noisy data accuracy: 0.4749\n",
      "\n",
      "Second Composed Model (LoRA 1 + LoRA 2):\n",
      "  Clean data accuracy: 0.9723\n",
      "  Noisy data accuracy: 0.8852\n",
      "\n",
      "âœ… All training complete!\n",
      "   - First LoRA adapter: ./vit_lora_adapter\n",
      "   - First merged model: ./vit_lora_merged\n",
      "   - Second LoRA adapter: ./vit_lora2_adapter\n",
      "   - Second merged model: ./vit_lora2_merged\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 16. Final Comparison\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test on clean data\n",
    "clean_eval_first = Trainer(\n",
    "    model=merged_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./temp\",\n",
    "        per_device_eval_batch_size=16,\n",
    "        remove_unused_columns=False,\n",
    "        report_to=\"none\"\n",
    "    ),\n",
    "    eval_dataset=val_dataset,\n",
    "    processing_class=processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    ").evaluate()\n",
    "\n",
    "clean_eval_second = Trainer(\n",
    "    model=second_merged_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./temp\",\n",
    "        per_device_eval_batch_size=16,\n",
    "        remove_unused_columns=False,\n",
    "        report_to=\"none\"\n",
    "    ),\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    ").evaluate()\n",
    "\n",
    "print(\"\\nðŸ“Š Performance Summary:\")\n",
    "print(\"\\nFirst Composed Model (LoRA 1):\")\n",
    "print(f\"  Clean data accuracy: {clean_eval_first['eval_accuracy']:.4f}\")\n",
    "print(f\"  Noisy data accuracy: {noisy_eval_results['eval_accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nSecond Composed Model (LoRA 1 + LoRA 2):\")\n",
    "print(f\"  Clean data accuracy: {clean_eval_second['eval_accuracy']:.4f}\")\n",
    "print(f\"  Noisy data accuracy: {second_eval_results['eval_accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nâœ… All training complete!\")\n",
    "print(\"   - First LoRA adapter: ./vit_lora_adapter\")\n",
    "print(\"   - First merged model: ./vit_lora_merged\")\n",
    "print(\"   - Second LoRA adapter: ./vit_lora2_adapter\")\n",
    "print(\"   - Second merged model: ./vit_lora2_merged\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
